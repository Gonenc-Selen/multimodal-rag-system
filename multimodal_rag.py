# -*- coding: utf-8 -*-
"""Multimodal RAG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xXeNNuPVOZCr9-s3LD8G20hThHXLgxlC
"""

pip install PyMuPDF

pip install faiss-cpu

import os #dosya içinde gezinme
import io #pdf'ten ayrıştırılan verileri vs bellekte tutmak için eklenir.
import base64 #binaryden stringe, stringden binary veri çevirme işlerinde kullanılır.
import numpy as np #Sayısal işlemler, matris ve vektör manipülasyonları için kullanılan güçlü bilimsel hesaplama kütüphanesidir.
from PIL import Image # Görselleri açmak, düzenlemek ve kaydetmek için kullanılan Python Imaging Library’nin (Pillow) temel sınıfıdır.
import fitz  # PyMUPDF #PDF dosyalarından metin ve görsel çıkarmak için kullanılan hafif ve hızlı bir belge işleme kütüphanesidir.
import torch #PyTorch framework'ünün çekirdeğidir; tensör işlemleri ve derin öğrenme modelleri için kullanılır.
import faiss #Yüksek boyutlu vektörler arasında hızlı benzerlik araması ve yakın komşu sorguları yapmak için kullanılır.
import gradio as gr #Makine öğrenmesi modellerine hızlıca web arayüzü oluşturmak için kullanılan kullanıcı dostu bir araçtır.
from typing import List,Dict, Tuple,Optional # Python'da statik tür ipuçları vererek kodun okunabilirliğini ve hatasızlığını artırmak için kullanılır.
from dataclasses import dataclass #Otomatik olarak __init__, __repr__ gibi metodları oluşturarak sade ve temiz veri sınıfları tanımlamayı sağlar.
from sentence_transformers import SentenceTransformer #Cümleleri vektörel temsillere dönüştürmek için kullanılan, BERT tabanlı hazır embedding modellerini sağlayan kütüphanedir.
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM,CLIPProcessor,CLIPModel, pipeline,AutoModelForSeq2SeqLM #Hugging Face Transformers kütüphanesinden, dil ve multimodal (metin + görsel) modelleri kullanmak için gerekli bileşenlerdir.
import json #JSON formatındaki verileri okumak ve yazmak için kullanılan yerleşik bir Python modülüdür.
import pickle #Python nesnelerini seri hale getirip diske kaydetmek veya geri yüklemek için kullanılır.
from tqdm import tqdm #Uzun süren döngülere ilerleme çubuğu (progress bar) ekleyerek işlemin durumunu görselleştiren araçtır.
import warnings # Uyarı mesajlarını yönetmek (gizlemek, özelleştirmek veya bastırmak) için kullanılan yerleşik Python modülüdür.
warnings.filterwarnings("ignore")
import re
from torch.nn.functional import normalize

# Data Structures
#dataclass_transform  # noqa: F841
@dataclass
class Document:
    """
    PDF içinden çıkan görselleri temsil eder.
    Attributes:
        text (str): Metin parçası.
        page_num (int): Metnin bulunduğu sayfa numarası.
        doc_name (str): PDF dosya adı.
        chunk_id (int): Parça sıralama kimliği.
    """
    text: str
    page_num: int
    doc_name: str
    chunk_id: int

@dataclass
class ImageData:
    """
    PDF içinden çıkan görselleri temsil eder.
    Attributes:
        image (Image.Image): PIL Image objesi.
        page_num (int): Görselin bulunduğu sayfa.
        doc_name (str): PDF dosya adı.
        image_id (int): Görsel sıralama kimliği.
        caption (str): Görsel açıklaması.
    """

    image: Image.Image
    page_num: int
    doc_name: str
    image_id: int
    caption: str = ""

class MultimodalRAG:
    def __init__(self, use_cuda=True):
        # Text işlemenin yapılacağı model indiriliyor. Cümleler vektöre çevrilecek.
        self.text_model = SentenceTransformer("sentence-transformers/all-mpnet-base-v2")
        # Görsel işleme için kullanılacak model indiriliyor. Görselleri vektöre çevirecek.
        # Bu kısım önceden eğitilmiş modeli indiriyor. Gelen parçaları vektöre çeviriyor.

        #Görsel ve vektör için verilen vektörleri ortak bir uzayda karşılaştırabilecek vektörler üretiyor.
        self.CLIPModel = CLIPModel.from_pretrained("laion/CLIP-ViT-H-14-laion2B-s32B-b79K")
        #Bu kısımda görselleri modele sokmak için uygun formata getiriyor.
        self.CLIPProcessor = CLIPProcessor.from_pretrained("laion/CLIP-ViT-H-14-laion2B-s32B-b79K")

        # 6) Cihaz ayarlar
        self.device ="cuda" if use_cuda and torch.cuda.is_available() else "cpu"
        self.text_model.to(self.device).eval()
        self.CLIPModel.to(self.device).eval()

        self.generator = pipeline ("text2text-generation", model="google/flan-t5-large", device=0 if self.device=="cuda" else -1, max_length=512, clean_up_tokenization_spaces=True)

        # 3) FAISS metin indeksi: embedding boyutuna göre L2 benzerliği/ En benzer vektörü bulur.
        self.text_index = faiss.IndexFlatL2(self.text_model.get_sentence_embedding_dimension())

        # 4) FAISS görsel indeksi: CLIP projeksiyon dimension
        dim_text = self.text_model.get_sentence_embedding_dimension()
        dim_img  = self.CLIPModel.config.projection_dim
        self.text_index  = faiss.IndexFlatL2(dim_text)   # L2
        self.image_index = faiss.IndexFlatIP(dim_img)    # IP (cosine için)

        # 5) Veri deposu: çıkarılan metin ve görseller listeleri
        self.documents: List[Document] = []
        self.images: List[ImageData] = []



    def clean_text(self,text: str) -> str:
        # URL'leri kaldır
        text = re.sub(r"http\S+", "", text)

        # HTML yorumlarını kaldır <!-- ... -->
        text = re.sub(r"<!--.*?-->", "", text)

        # "image", "--", "===", "___" gibi yapıları kaldır
        text = re.sub(r"\bimage\b", "", text, flags=re.IGNORECASE)
        text = re.sub(r"(--+|==+|__+)", " ", text)

        # "2024 UYARI ... ." gibi yapıları sadeleştir
        text = re.sub(r"\d{4}\s*UYARI.*?\.", ".", text)

        # Türkçe karakterleri koruyarak özel karakterleri kaldır
        text = re.sub(r"[^A-Za-zÇçĞğİıÖöŞşÜü0-9.,;:%&()\-\"'?!\s]", " ", text)

        # Fazla boşlukları tek boşluğa indir
        text = re.sub(r"\s+", " ", text).strip()

        return text


    def extract_text_from_pdf(self, file_path: str, chunk_size: int = 500) -> List[Document]:
        docs: List[Document] = []
        name = os.path.basename(file_path)
        pdf = fitz.open(file_path)
        for i in range(pdf.page_count):

            raw = pdf[i].get_text()
            text= self.clean_text(raw)
            words = text.split()
            for j in range(0, len(words), chunk_size):
                chunk = " ".join(words[j:j+chunk_size])
                if chunk:
                    docs.append(Document(text=chunk, page_num=i+1, doc_name=name, chunk_id=len(docs)))
        pdf.close()
        return docs

    def extract_images_from_pdf(self, file_path: str) -> List[ImageData]:
        """
        PDF'ten görseller çıkarır.
        Args:
            file_path: PDF dosya yolu.
        Returns:
            Görsel bilgileri içeren ImageData listesi.
        """
        #Bu, elde edilecek tüm resimlerin saklanacağı boş liste.Her eleman bir ImageData nesnesi olacak.
        imgs: List[ImageData] = []

        #Dosya yolundan sadece dosya adını alır.
        name = os.path.basename(file_path)

        #Sayfaların içeriğine erişilebilir.
        pdf = fitz.open(file_path)

        #Sayfa sayfa gezer
        for i in range(pdf.page_count):
           #Sayfa içerisindeki tüm resimleri alır.
            for img in pdf.get_page_images(i, full=True):
                #xref PDF içindeki görsele verilen referans numarasıdır.
                #Bu referasnla görselin piksel verisini erişilir.
                xref = img[0]
                # PDF içindeki bu xref görseli piksel formatında (Pixmap) yükler.
                pix = fitz.Pixmap(pdf, xref)

                #Resmin 4. kanalı var mı diye kontrol ediyor? Apha seffaflık kanalıymış. Kanal sayısı 4'ün altındaysa işlemeye başlıyor.
                if pix.n - pix.alpha < 4:
                    #Resimler farklı formatlarda olabileceği için png formatına dönüştürülüyor byte tipinde png formatında dosyalar oluşuyor.
                    img_bytes = pix.tobytes("png")
                    #Bu görseller sonra Python Imaging Library objesine dönüştürülüyor.
                    pil = Image.open(io.BytesIO(img_bytes))
                    # Ardından ImageData içerisine ekranda göstermek istediğimiz bilgiler ekleniyor.
                    imgs.append(ImageData(image=pil, page_num=i+1, doc_name=name, image_id=len(imgs), caption=f"Image from {name}, page {i+1}"))
                #Hafızayı boşaltmak için sonra None değeri atanıyor.
                pix = None
         #PDF dosyası kapatılıyor.
        pdf.close()
        return imgs

    #Vektör oluşturmak için kullanılan fonksiyondur. Oluşturulan List Document burada fonksiyon içerisinde girer ve
    def embed_texts(self, docs: List[Document]) -> np.ndarray:

       """
        Document listesindeki metinleri embed vektörlerine dönüştürür.
        Returns:
            2D numpy array (float32) of embeddings.
        """
       texts = [d.text for d in docs]    # Sadece metin parçalarını al
       return self.text_model.encode(texts, show_progress_bar=False).astype("float32") #encode et ve vektörleştir.


    #Vektör oluşturmak için kullanılan fonksiyondur. Oluşturulan List Document burada fonksiyon içerisinde girer ve
    def embed_images(self, imgs: List[ImageData]) -> np.ndarray:

       """
         Görselleri CLIP ile embed eder
        Returns:
            2D numpy array (float32) of image embeddings.
        """

       if not imgs:
          return np.zeros(
            (0, self.CLIPModel.config.projection_dim),dtype="float32")

       # 1) Görselleri listele
       pil_images = [imgd.image for imgd in imgs]

       # 2) Tek seferde processor
       inputs = self.CLIPProcessor(images=pil_images, return_tensors="pt",padding=True)

       # 3) Cihaz ayarı
       inputs = {k: v.to(self.device) for k, v in inputs.items()}

       # 4) Tek seferde inferans
       with torch.no_grad():
          feats = self.CLIPModel.get_image_features(**inputs)  # Tensor [N, 512]

       # 5) Normalize et (unit‐norm)
       feats = normalize(feats, dim=-1)

       # 6) CPU’ya taşı ve NumPy’ye çevir
       return feats.cpu().numpy().astype("float32")  # (N, 512)

    def process_pdfs(self, paths: List[str]):
        """
        Birden fazla PDF yolunu işleyip metin ve görsel indekslerini günceller.
        """
        #Yukarıda yazılan fonksiyonları burada çağırarak pdf'teki görsel ve metinleri işler.
        #Önce pdf textlerini ve imageları çıkarıyor. Ardından bunları indeksleyip liste ve image embeding'e ekler.

        self.text_index.reset()
        self.image_index.reset()

        all_docs, all_imgs = [], []

        for p in paths:
            all_docs.extend(self.extract_text_from_pdf(p))
            all_imgs.extend(self.extract_images_from_pdf(p))
        self.documents, self.images = all_docs, all_imgs

        if self.documents:
            emb = self.embed_texts(self.documents)
            self.text_index.add(emb)

        if self.images:
            emb = self.embed_images(self.images)
            faiss.normalize_L2(emb)
            self.image_index.add(emb)
        print(f"Processed {len(all_docs)} text chunks and {len(all_imgs)} images.")


    #Kullanıcının yazdığı metin: query -- > Sonuç olarak da en yakın 5 adet sonuç bir tuple içinde döndürülür.
    def search_text(self, query: str, k: int = 5) -> List[Tuple[Document, float]]:
        """
        Soru metnini embed edip en yakın k metin parçasını döndürür.
        Returns list of (Document, distance).
        """
        if not self.documents:
            return []
        #Kullanıcıdan gelen query vektöre çevrilir
        q = self.text_model.encode([query]).astype("float32")
        #Text index içerisindeki en yakın 5 tane vektörü getirir. i --> index numarası, d --> mesafe bilgisini döner.
        d, i = self.text_index.search(q, k)
        # Fonksiyon şu çıktıyı verir: [(Document(text="...", page_num=3, ...), 0.12),Document(text="...", page_num=5, ...), 0.23),]
        return [(self.documents[idx], float(dist)) for idx, dist in zip(i[0], d[0]) if idx < len(self.documents)]

    def rerank_images (self, query: str, candidates: list[ImageData], k: int):
        """
         CLIP ile text ve image özelliklerini çıkarıp cosine benzerlikle sırala
        """
        texts = [query] * len(candidates)
        imgs  = [c.image for c in candidates]
        # Metin ve görsel girişlerini ayrı ayrı işleyin
        text_inputs = self.CLIPProcessor(text=texts, return_tensors="pt", padding=True).to(self.device)
        image_inputs = self.CLIPProcessor(images=imgs, return_tensors="pt", padding=True).to(self.device)

        with torch.no_grad():
            t_feats = self.CLIPModel.get_text_features(**text_inputs)
            i_feats = self.CLIPModel.get_image_features(**image_inputs)
            t_feats = normalize(t_feats, dim=-1)
            i_feats = normalize(i_feats, dim=-1)
            sims = (t_feats * i_feats).sum(dim=-1).cpu().numpy()
         # En yüksek k sim ile eşleşenleri sırala
        idxs = np.argsort(-sims)[:k]
        return [(candidates[i], float(sims[i])) for i in idxs]

    def search_images(self, query: str, k: int = 5) -> List[Tuple[ImageData, float]]:
        """
        1) IndexFlatIP ile cosine‐benzerliği hızlıca bul,
        2) sonra rerank_images ile en alakalı k tanesini döndür.
        """
        inputs = self.CLIPProcessor(text=[query], return_tensors="pt").to(self.device)
        with torch.no_grad():
          q_feat = self.CLIPModel.get_text_features(**inputs)
          q_feat = normalize(q_feat, dim=-1).cpu().numpy().astype("float32")

        # 2) FAISS(IP) araması
        initial_k = k * 4
        initial_k = min(initial_k, len(self.images))
        # Also add a check here to prevent FAISS search with k=0 if initial_k somehow becomes 0
        if initial_k == 0:
            return []
        dists, idxs = self.image_index.search(q_feat, initial_k)
        candidates = [self.images[i] for i in idxs[0]]

        # 3) CLIP ile rerank
        return self.rerank_images(query, candidates, k)

    def generate_response(self, query: str, texts: List[Tuple[Document, float]], imgs: List[Tuple[ImageData, float]]) -> str:
        """
        Arama sonuçlarını birleştirerek kullanıcıya okunabilir, belirli bir şablona uygun bir yanıt üretir.
        Prompt yapısı, ilgili metin bağlamını daha fazla vurgulayacak şekilde güncellendi.
        """
        # Top metin parçalarını hazırla (sayıyı 3'te tuttuk)
        text_ctx = "\n".join(f"- (p{doc.page_num}) {doc.text}" for doc, _ in texts[:1]) # 3 text chunk

        # Top görsel başlıklarını hazırla (sayıyı 2'de tuttuk)
        img_ctx = "\n".join(f"- (Image p{img.page_num}) {img.caption}" for img, _ in imgs[:1]) # 2 image caption

        # Prompt’u oluştur - Metin bağlamını daha fazla vurgulayan ve detay isteyen İngilizce yapı
        prompt = (
          f"Using the following context, explain and discuss the answer to the question: '{query}'.\n" # 'explain and discuss' ekleyerek yorumlama isteğimizi belirttik
          f"Refer to the text and image information provided.\n\n" # Genel referans isteği
          f"**Context:**\n"
          f"{text_ctx}\n"
          f"{img_ctx}\n\n"
          f"**Answer:**" # Yanıt başlangıcı
        )

        # Doğrudan pipeline'ı kullanarak metin üretin. Tokenization pipeline içinde yapılır.
        # max_new_tokens 400'de, num_beams 4'te kaldı.
        output = self.generator(prompt, max_new_tokens=400, num_beams=7, no_repeat_ngram_size=2)

        # Çıktıyı döndürüyoruz. Yanıt artık İngilizce olacaktır.
        return output[0]["generated_text"].strip()

# Sistemi başlat
rag_system = MultimodalRAG()

path= "/content/ABSA.pdf"
rag_system.process_pdfs([path])

# Arama sonuçlarını alın (k değerlerini önceki ayarlarda tutalım)
txt_res = rag_system.search_text("Laguna Tedarikçisinin Sülfür Oranı 0.71 Olarak Değiştirilmesi durumunda ne olur?", k=3)
imgs_res = rag_system.search_images("Laguna Tedarikçisinin Sülfür Oranı 0.71 Olarak Değiştirilmesi durumunda ne olur?", k=2)

print("Text Search Results:")
if txt_res:
    for doc, dist in txt_res:
        print(f"- Doc: {doc.doc_name}, Page: {doc.page_num}, Dist: {dist:.4f}")
        print(f"  Text: {doc.text[:200]}...") # Metnin ilk 200 karakterini yazdıralım
else:
    print("No text results found.")

print("\nImage Search Results:")
if imgs_res:
    for img, dist in imgs_res:
        print(f"- Doc: {img.doc_name}, Page: {img.page_num}, Image ID: {img.image_id}, Dist: {dist:.4f}")
        print(f"  Caption: {img.caption}")
        # İsteğe bağlı: Görseli göstermek için
        # display(img.image.resize((100, 100))) # Küçük boyutta gösterelim
else:
    print("No image results found.")

# Ardından generate_response'u çalıştırın:
# print(rag_system.generate_response("Nominal value nedir?", txt_res, imgs_res))

txt = rag_system.search_text("Explain Ordinal value?", k=1)
imgs = rag_system.search_images("Explain Ordinal value?", k=1)
print(rag_system.generate_response("Explain Ordinal value?", txt, imgs))

# Gradio fonksiyonları
def gradio_upload_pdfs(files: List[gr.File]):
    if not files:
        return "⚠️ Lütfen PDF dosyası yükleyin."
    paths = []
    for f in files:
        # Kendi yönteminle kaydetme
        temp_path = f.name if hasattr(f, 'name') else None
        if temp_path:
            paths.append(temp_path)
    try:
        rag_system.process_pdfs(paths)
        return f"✅ {len(paths)} PDF işlendi."
    except Exception as e:
        return f"PDF işleme hatası: {e}"


def gradio_answer_question(query: str):
    if not rag_system.documents:
        return "⚠️ Lütfen önce PDF yükleyin.", None
    if not query.strip():
        return "⚠️ Lütfen bir soru girin.", None
    try:
        txt_res = rag_system.search_text(query, k=5)
        img_res = rag_system.search_images(query, k=2)
        resp = rag_system.generate_response(query, txt_res, img_res)
        img_path: Optional[str] = None
        if img_res:
            img_obj = img_res[0][0]
            tmp = f"/tmp/{img_obj.doc_name}_p{img_obj.page_num}_img{img_obj.image_id}.png"
            img_obj.image.save(tmp)
            img_path = tmp
        return resp, img_path
    except Exception as e:
        return f"Cevap oluşturma hatası: {e}", None

with gr.Blocks() as demo:
    gr.Markdown("## 📄 Multimodal RAG: PDF + Görsel Soru-Cevap Arayüzü")
    with gr.Tab("1️⃣ PDF Yükle"):
        up = gr.File(file_types=[".pdf"], file_count="multiple", label="PDF Yükle")
        out1 = gr.Markdown()
        # Otomatik tetikleme
        up.change(fn=gradio_upload_pdfs, inputs=[up], outputs=[out1])
        # Elle tetikleme alternatifi
        btn1 = gr.Button("İşle")
        btn1.click(fn=gradio_upload_pdfs, inputs=[up], outputs=[out1])
    with gr.Tab("2️⃣ Soru Sor"):
        q_in = gr.Textbox(label="Sorunuz", placeholder="Nominal Value nedir?")
        btn2 = gr.Button("Sor")
        out2 = gr.Markdown(label="Yanıt")
        img2 = gr.Image(label="Eşleşen Görsel", type="filepath")
        btn2.click(fn=gradio_answer_question, inputs=[q_in], outputs=[out2, img2])

if __name__ == "__main__":
    demo.launch()

